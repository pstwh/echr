{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'ech_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = !ls echr_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in articles:\n",
    "    path = f'{DATA}/{article}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cases_a6.csv\t\t     ngrams_a6_full.csv       ngrams_a6_relevantLaw.csv\r\n",
      "ngrams_a6_circumstances.csv  ngrams_a6_law.csv\t      topics6.csv\r\n",
      "ngrams_a6_featureNames.txt   ngrams_a6_procedure.csv  topics6_vocab.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls echr_dataset/Article6/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(path, features):\n",
    "    files_raw = !ls {path}\n",
    "    files_features = ['cases', 'circumstances', 'featureNames', 'full', 'law', 'procedure', 'relevantLaw', 'topics', 'topicsVocab']\n",
    "    files = dict(zip(files_features, files_raw))\n",
    "    \n",
    "    group = []\n",
    "    for feature in features:\n",
    "        if(feature == 'topics'): raw = pd.read_csv(path+files[feature], sep='\\t', header=None)\n",
    "        elif(feature == 'topicsVocab'): raw = open(path+files[feature]).read(); raw.replace('\\n', '').replace(', ', ',').split(',')\n",
    "        else: raw = pd.read_csv(path+files[feature], header=None)\n",
    "        \n",
    "        if feature == 'cases': raw = raw[1]\n",
    "            \n",
    "        group.append(raw)\n",
    "    return pd.concat(group, axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article3  Article6  Article8\r\n"
     ]
    }
   ],
   "source": [
    "!ls echr_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_article('echr_dataset/Article8/', ['cases', 'full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000]},\n",
    "    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(preprocessing.StandardScaler(), \n",
    "                    GridSearchCV(SVC(),\n",
    "                                 param_grid=param_grid, cv=10, refit=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7115384615384616"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
